{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "from math import atan, sqrt, degrees\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pypcd import pypcd\n",
    "from decimal import Decimal\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory          = r\"/media/tmn/mySataSSD1/DATASETS/MCDVIRAL/MCDImage/ntu_day_01/img/\"\n",
    "point_cloud_directory    = r\"/media/tmn/mySataSSD1/DATASETS/MCDVIRAL/MCDPointCloud/ntu_day_01/inB/\"    \n",
    "yolo_detects_directory   = r\"/media/tmn/mySataSSD1/DATASETS/MCDVIRAL/NTU_World_Cars/yolov7/runs/detect/\"\n",
    "pose_inW                 = pd.read_csv(\"/media/tmn/mySataSSD1/DATASETS/MCDVIRAL/MCDPointCloud/ntu_day_01/pose_inW.csv\")\n",
    "pc_inW_deskewed_filename = \"/media/tmn/mySataSSD1/DATASETS/MCDVIRAL/NTU_World_Cars/yolov7/world_2_new_point_cloud.pcd\"\n",
    "class_choice             = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_number(number_list, target_number):\n",
    "    nearest_number = None\n",
    "    min_difference = float('inf')  # Initialize with a large value\n",
    "\n",
    "    for num in number_list:\n",
    "        difference = abs(num - target_number)\n",
    "        if difference < min_difference:\n",
    "            min_difference = difference\n",
    "            nearest_number = num\n",
    "\n",
    "    return nearest_number\n",
    "\n",
    "def depth_to_color(depth, colormap=cv2.COLORMAP_JET):\n",
    "    normalized_depth = (depth - np.min(depth)) / (np.max(depth) - np.min(depth))\n",
    "    color_map = cv2.applyColorMap(np.uint8(255 * normalized_depth), colormap)\n",
    "    return color_map\n",
    "\n",
    "def map_value(x, a, b, c, d):\n",
    "    return c + (x - a) * (d - c) / (b - a)\n",
    "\n",
    "def distort(x, y, k1, k2, p1, p2):\n",
    "\n",
    "    rsq = x**2 + y**2\n",
    "\n",
    "    x_dist = x*(1 + k1*rsq + k2*(rsq**2)) + 2*p1*x*y + p2*(rsq + 2*(x**2))\n",
    "    y_dist = y*(1 + k1*rsq + k2*(rsq**2)) + p1*(rsq + 2*(y**2)) + p2*x*y\n",
    "\n",
    "    return [x_dist, y_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some user defined functions\n",
    "\n",
    " \n",
    "\n",
    "# Quaternion multiplication\n",
    "from evo.core.transformations import quaternion_multiply as quatmult\n",
    "# Conversion between quat and rotm\n",
    "from evo.core.transformations import quaternion_matrix as quat2rotm_\n",
    "from evo.core.transformations import quaternion_from_matrix as rotm2quat\n",
    "# Conversion between eul angles and rotm\n",
    "from evo.core.transformations import euler_matrix as eul2rotm_\n",
    "from evo.core.transformations import euler_from_matrix as rotm2eul_\n",
    "\n",
    " \n",
    "\n",
    "def quat2rotm(q): return quat2rotm_(q)[0:3, 0:3]\n",
    "def eul2rotm(e0, e1, e2): return eul2rotm_(e0, e1, e2, 'rzyx')[0:3, 0:3]\n",
    "def rotm2eul(M): return rotm2eul_(M, 'rzyx')\n",
    "\n",
    " \n",
    "\n",
    "# Extra definition for euler and quaternion\n",
    "def eul2quat(e0, e1, e2): return rotm2quat(eul2rotm(e0, e1, e2))\n",
    "def quat2eul(q): return rotm2eul(quat2rotm(q))\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "def pose2Tf(pose):\n",
    "    q = pose[0, [6, 3, 4, 5]]\n",
    "    t = np.reshape(pose[0, [0, 1, 2]], (3, 1))\n",
    "    return Qt2Tf(q, t)\n",
    "\n",
    " \n",
    "\n",
    "def Tf2Qt(T):\n",
    "    q = rotm2quat(T[0:3, 0:3])\n",
    "    t = T[0:3, 3:4]\n",
    "    return q, t\n",
    "\n",
    " \n",
    "\n",
    "def Qt2Tf(q, t):\n",
    "    T = np.identity(4)\n",
    "    T[0:3, 0:3] = quat2rotm(q)\n",
    "    T[0:3, 3:4] = t\n",
    "    return T\n",
    "\n",
    " \n",
    "\n",
    "def Rt2Tf(R, t):\n",
    "    T = np.identity(4)\n",
    "    T[0:3, 0:3] = R\n",
    "    T[0:3, 3:4] = t\n",
    "    return T\n",
    "\n",
    " \n",
    "\n",
    "def Tf2Rt(T):\n",
    "    return (T[0:3, 0:3], T[0:3, 3:4])\n",
    "\n",
    " \n",
    "\n",
    "def tfinv(T):\n",
    "    R = T[0:3, 0:3].copy()\n",
    "    t = T[0:3, 3:4].copy()\n",
    "    R = R.transpose()\n",
    "    t = np.dot(R, t)*(-1)\n",
    "    return Rt2Tf(R, t)\n",
    "\n",
    " \n",
    "\n",
    "def tfmult(T1, T2):\n",
    "\n",
    "    R1 = T1[0:3, 0:3].copy()\n",
    "    t1 = T1[0:3, 3:4].copy()\n",
    "\n",
    " \n",
    "\n",
    "    R2 = T2[0:3, 0:3].copy()\n",
    "    t2 = T2[0:3, 3:4].copy()\n",
    "\n",
    " \n",
    "\n",
    "    R = np.dot(R1, R2)\n",
    "    t = np.dot(R1, t2) + t1\n",
    "    return Rt2Tf(R, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "world_points=[]\n",
    "\n",
    "T_B_C = np.array([[-0.01507104171318285, 0.005988709007546782, 0.9998684908857283,   0.05666674638032021],\n",
    "                  [ 0.9998528146297833, -0.008108860850700655, 0.015119373419753048, 0.01100640924886362],\n",
    "                  [ 0.00819833998937974, 0.9999491895792147,  -0.005865618577067036, 0.11440342483060817],\n",
    "                  [ 0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "intrinsics= [383.9298163754784, 382.9589851049001, 322.81111219908314, 250.9729552053214]\n",
    "\n",
    "distortion_coeffs= [-0.04406471805202435, 0.04043629293187546, -1.2130737779239174e-06, 0.0018435172104962858]\n",
    "\n",
    "d455b_fov=[90, 65] #in degrees\n",
    "\n",
    "T_C_B = tfinv(T_B_C)\n",
    "\n",
    "yolo_exp_file_number=2\n",
    "\n",
    "pose_inW['t'] = pose_inW['t'].apply(lambda x: Decimal(x))\n",
    "\n",
    "time_str=[]\n",
    "\n",
    "for i in pose_inW['t']:\n",
    "\n",
    "    time_str.append(str(Decimal(i))[:20])\n",
    "\n",
    "pose_inW['time_str']=time_str\n",
    "\n",
    "for point_cloud_file in os.listdir(point_cloud_directory):\n",
    "\n",
    "    first_index = point_cloud_file.index('_')\n",
    "\n",
    "    second_index = point_cloud_file.index('_', first_index + 1)\n",
    "\n",
    "    third_index = point_cloud_file.index('_', second_index + 1)\n",
    "\n",
    "    fourth_index = point_cloud_file.index('.')\n",
    "\n",
    "    point_cloud_second = point_cloud_file[second_index+1:third_index]\n",
    "    point_cloud_nanosec = point_cloud_file[third_index+1:fourth_index]\n",
    "\n",
    "    closest_imgs=[]\n",
    "\n",
    "    for filename in os.listdir(image_directory):\n",
    "\n",
    "        index_1 = filename.index('_')\n",
    "        index_2 = filename.index('_', index_1 + 1)\n",
    "        index_3 = filename.index('_', index_2 + 1)\n",
    "        index_4 = filename.index('.')\n",
    "\n",
    "        if filename[index_2+1: index_3]==point_cloud_second:\n",
    "\n",
    "            closest_imgs.append(int(filename[index_3 + 1: filename.index('.')]))\n",
    "\n",
    "    closest_img=find_nearest_number(closest_imgs, int(point_cloud_nanosec))\n",
    "\n",
    "    for pic in os.listdir(image_directory):\n",
    "\n",
    "        index_1 = pic.index('_')\n",
    "        index_2 = pic.index('_', index_1 + 1)\n",
    "        index_3 = pic.index('_', index_2 + 1)\n",
    "        index_4 = pic.index('.')\n",
    "\n",
    "        if pic[index_2+1 :]== point_cloud_second + '_' + str(closest_img) + '.png':\n",
    "\n",
    "            image_path=image_directory + pic\n",
    "\n",
    "    !python3 detect.py --weights yolov7-e6e.pt --conf 0.25 --img-size 1280 --source {image_path} --save-txt\n",
    "\n",
    "    yolo_exp_file_path = yolo_detects_directory + \"exp\" + str(yolo_exp_file_number)\n",
    "    yolo_exp_file_number =  yolo_exp_file_number + 1\n",
    "\n",
    "    yolo_preds_label_directory = os.path.join(yolo_exp_file_path, \"labels\")\n",
    "\n",
    "    if len(os.listdir(yolo_preds_label_directory))>0:\n",
    "\n",
    "        for file in os.listdir(yolo_exp_file_path):\n",
    "\n",
    "            yolo_preds_file_path = os.path.join(yolo_exp_file_path, file)\n",
    "\n",
    "            if file.endswith('.png'):\n",
    "                \n",
    "                yolo_pred_image_path = yolo_preds_file_path\n",
    "\n",
    "        for label_file in os.listdir(yolo_preds_label_directory):\n",
    "\n",
    "            yolo_pred_image_labels_path = os.path.join(yolo_preds_label_directory, label_file)\n",
    "\n",
    "        point_cloud = pypcd.PointCloud.from_path(os.path.join(point_cloud_directory, point_cloud_file))\n",
    "        points_xyz = np.asarray(point_cloud.pc_data[['x', 'y', 'z']])\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        with open(yolo_pred_image_labels_path, 'r') as file:\n",
    "            content = file.read().split('\\n')\n",
    "            content.pop()\n",
    "            \n",
    "        coords_list=[]\n",
    "\n",
    "        for i in content:\n",
    "            if not (int(i[:2])==class_choice):\n",
    "                content.remove(i)\n",
    "\n",
    "        for object in content:\n",
    "\n",
    "            point_cloud_coords=object.split(' ')\n",
    "            point_cloud_coords[1]=float(point_cloud_coords[1])*image.shape[1]\n",
    "            point_cloud_coords[2]=float(point_cloud_coords[2])*image.shape[0]\n",
    "            point_cloud_coords[3]=float(point_cloud_coords[3])*image.shape[1]\n",
    "            point_cloud_coords[4]=float(point_cloud_coords[4])*image.shape[0]\n",
    "            coords_list.append(point_cloud_coords[1:])\n",
    "\n",
    "        camera_points=[]\n",
    "        pixel_coords=[]\n",
    "        distorted_points=[]\n",
    "\n",
    "        index=0\n",
    "\n",
    "        for body in points_xyz:\n",
    "            \n",
    "            body = np.append(list(body), 1)\n",
    "\n",
    "            camera_coord = np.dot(T_C_B, body)\n",
    "\n",
    "            if (-45<degrees(atan(camera_coord[0]/sqrt(camera_coord[1]**2+camera_coord[2]**2)))<45) and (-32.5<degrees(atan(camera_coord[1]/sqrt(camera_coord[0]**2+camera_coord[2]**2)))<32.5) and camera_coord[2]>0:\n",
    "\n",
    "                camera_points.append(camera_coord[:3])\n",
    "\n",
    "                noramlized_points = (camera_coord[:3]/camera_coord[2])[:2]\n",
    "\n",
    "                distorted_points = distort(noramlized_points[0], noramlized_points[1], distortion_coeffs[0], distortion_coeffs[1], distortion_coeffs[2], distortion_coeffs[3])\n",
    "\n",
    "                pixel_coords.append([distorted_points[0]*intrinsics[0]+intrinsics[2], distorted_points[1]*intrinsics[1]+intrinsics[3], camera_coord[2], index])\n",
    "\n",
    "            index = index+1\n",
    "\n",
    "        camera_points = np.array(camera_points)\n",
    "        pixel_coords = np.array(pixel_coords)\n",
    "\n",
    "        z_coordinates = [i[2] for i in pixel_coords]\n",
    "\n",
    "        # Normalize the z-coordinates to the range [0, 1]\n",
    "        normalized_z = (z_coordinates - np.min(z_coordinates)) / (np.max(z_coordinates) - np.min(z_coordinates))\n",
    "\n",
    "        # Replace the original z-coordinates with the normalized values\n",
    "        pixel_coords[:, 2] = [int(i*255) for i in normalized_z]\n",
    "\n",
    "        pc_index=[]\n",
    "\n",
    "        if image is None:\n",
    "            print(\"Error: Could not read the image\")\n",
    "        else:\n",
    "            for coord in pixel_coords:\n",
    "                x, y = int(coord[0]), int(coord[1])\n",
    "                z = int(coord[2])\n",
    "                bgr_color = cv2.cvtColor(np.array([[(z, 255, 255)]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0][0]\n",
    "                bgr_color = (int(bgr_color[0]), int(bgr_color[1]), int(bgr_color[2]))\n",
    "\n",
    "                for object in coords_list:\n",
    "                    if x>(object[0]-(object[2]/2)) and x<(object[0]+(object[2]/2)) and y>(object[1]-(object[3]/2)) and y<(object[1]+(object[3]/2)):\n",
    "\n",
    "                        cv2.circle(image, (x, y), radius=1, color=bgr_color, thickness=-1)\n",
    "\n",
    "                        pc_index.append(coord[3])\n",
    "\n",
    "\n",
    "        points = np.asarray(point_cloud.pc_data[['x', 'y', 'z', 'intensity']])\n",
    "\n",
    "        detected_pc=[]\n",
    "\n",
    "        for i in pc_index:\n",
    "\n",
    "            detected_pc.append(list(points[int(i)]))\n",
    "\n",
    "        detected_pc=np.array(detected_pc)\n",
    "\n",
    "        csv_value = find_nearest_number([int(i[11:20]) for i in pose_inW['time_str']], int(point_cloud_nanosec))\n",
    "\n",
    "        xb_world = pose_inW[pose_inW['time_str'] == (point_cloud_second + '.' + str(csv_value))]['x']\n",
    "        yb_world = pose_inW[pose_inW['time_str'] == (point_cloud_second + '.' + str(csv_value))]['y']\n",
    "        zb_world = pose_inW[pose_inW['time_str'] == (point_cloud_second + '.' + str(csv_value))]['z']\n",
    "        qx_world = pose_inW[pose_inW['time_str'] == (point_cloud_second + '.' + str(csv_value))]['qx']\n",
    "        qy_world = pose_inW[pose_inW['time_str'] == (point_cloud_second + '.' + str(csv_value))]['qy']\n",
    "        qz_world = pose_inW[pose_inW['time_str'] == (point_cloud_second + '.' + str(csv_value))]['qz']\n",
    "        qw_world = pose_inW[pose_inW['time_str'] == (point_cloud_second + '.' + str(csv_value))]['qw']\n",
    "        \n",
    "        quaternions = np.column_stack((qx_world, qy_world, qz_world, qw_world))\n",
    "        rotations = R.from_quat(quaternions)\n",
    "\n",
    "        world_data = pd.DataFrame(columns=['Points'])\n",
    "        world_data.to_csv('world_data_cars.csv', index=False)\n",
    "\n",
    "        for i in detected_pc:\n",
    "\n",
    "            detected_points = np.column_stack((i[0], i[1], i[2]))\n",
    "\n",
    "            try:\n",
    "\n",
    "                rotated_points = rotations.apply(detected_points)\n",
    "\n",
    "            except ValueError:\n",
    "\n",
    "                continue\n",
    "\n",
    "            rotated_points[0][0]=rotated_points[0][0]+xb_world\n",
    "            rotated_points[0][1]=rotated_points[0][1]+yb_world\n",
    "            rotated_points[0][2]=rotated_points[0][2]+zb_world\n",
    "\n",
    "            i[0] = rotated_points[0][0]\n",
    "            i[1] = rotated_points[0][1]\n",
    "            i[2] = rotated_points[0][2]\n",
    "\n",
    "            world_points.append(i)\n",
    "\n",
    "        world_data['Points'] = world_points       \n",
    "        world_data.to_csv('world_data_cars.csv', index=False)    \n",
    "        \n",
    "    else:\n",
    "\n",
    "        continue\n",
    "\n",
    "\n",
    "    \n",
    "           \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = pd.read_csv('world_data_cars.csv')\n",
    "\n",
    "import re\n",
    "import ast\n",
    "\n",
    "def extract_numbers_from_string(input_string):\n",
    "    number_pattern = r'-?\\d+(?:\\.\\d+)?(?:e[+-]?\\d+)?'\n",
    "    number_matches = re.findall(number_pattern, input_string)\n",
    "    number_list = [float(match) if '.' in match or 'e' in match.lower() else int(match) for match in number_matches]\n",
    "    return number_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points=[]\n",
    "\n",
    "for i in wp['Points']:\n",
    "\n",
    "    all_points.append(extract_numbers_from_string(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pypcd.save_point_cloud_bin_compressed(\n",
    "\n",
    "                pypcd.PointCloud.from_array(np.array(list(map(tuple, all_points)), dtype=[('x', '<f4'),\n",
    "\n",
    "                                                                                               ('y', '<f4'),\n",
    "\n",
    "                                                                                               ('z', '<f4'),\n",
    "\n",
    "                                                                                               ('intensity', '<f4')])), pc_inW_deskewed_filename)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
